{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8692c0f6-0c8e-49c4-b3bb-cdafcbef427e",
   "metadata": {},
   "source": [
    "# 2. Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04bff564-960a-4839-87f5-f36582b48f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# moving avergae forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dd6e9f0-0822-4811-b9fd-b614c8837737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/jupyterlab/bin/python3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce3e40dd-9002-4032-919a-ac2f99ee1e35",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_15609/2443899097.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66523512-9d25-4310-879b-af469572d8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train = pd.read_parquet('../data/train.parquet')\n",
    "test = pd.read_parquet('../data/test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "075b209e-dfa6-43ae-bdfa-fe95adfaba57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day_id</th>\n",
       "      <th>but_num_business_unit</th>\n",
       "      <th>dpt_num_department</th>\n",
       "      <th>turnover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>64</td>\n",
       "      <td>127</td>\n",
       "      <td>580.308443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>119</td>\n",
       "      <td>127</td>\n",
       "      <td>1512.995918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>4</td>\n",
       "      <td>88</td>\n",
       "      <td>668.593556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>425</td>\n",
       "      <td>127</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>513</td>\n",
       "      <td>73</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       day_id  but_num_business_unit  dpt_num_department     turnover\n",
       "0  2017-09-30                     64                 127   580.308443\n",
       "1  2017-09-30                    119                 127  1512.995918\n",
       "2  2017-09-30                      4                  88   668.593556\n",
       "3  2017-09-30                    425                 127     0.000000\n",
       "4  2017-09-30                    513                  73     0.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8c09ba5-7d7d-40f8-aeb3-041c518dc3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['day'] = pd.to_datetime(train['day_id'])\n",
    "train['week'] = train['day'].dt.isocalendar().week\n",
    "train['month'] = train['day'].dt.month\n",
    "train['year'] = train['day'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94dcb6e2-c2ea-4fbb-9a3d-81019c0755a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['day'] = pd.to_datetime(test['day_id'])\n",
    "test['week'] = test['day'].dt.isocalendar().week\n",
    "test['month'] = test['day'].dt.month\n",
    "test['year'] = test['day'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd022276-4b06-41c1-811e-2d4c7223f6c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day_id</th>\n",
       "      <th>but_num_business_unit</th>\n",
       "      <th>dpt_num_department</th>\n",
       "      <th>turnover</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>64</td>\n",
       "      <td>127</td>\n",
       "      <td>580.308443</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>39</td>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>119</td>\n",
       "      <td>127</td>\n",
       "      <td>1512.995918</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>39</td>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>4</td>\n",
       "      <td>88</td>\n",
       "      <td>668.593556</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>39</td>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>425</td>\n",
       "      <td>127</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>39</td>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>513</td>\n",
       "      <td>73</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>39</td>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277714</th>\n",
       "      <td>2012-12-29</td>\n",
       "      <td>131</td>\n",
       "      <td>73</td>\n",
       "      <td>1.461821</td>\n",
       "      <td>2012-12-29</td>\n",
       "      <td>52</td>\n",
       "      <td>12</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277715</th>\n",
       "      <td>2012-12-29</td>\n",
       "      <td>237</td>\n",
       "      <td>127</td>\n",
       "      <td>759.283046</td>\n",
       "      <td>2012-12-29</td>\n",
       "      <td>52</td>\n",
       "      <td>12</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277716</th>\n",
       "      <td>2012-12-29</td>\n",
       "      <td>129</td>\n",
       "      <td>117</td>\n",
       "      <td>1716.399152</td>\n",
       "      <td>2012-12-29</td>\n",
       "      <td>52</td>\n",
       "      <td>12</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277717</th>\n",
       "      <td>2012-12-29</td>\n",
       "      <td>468</td>\n",
       "      <td>127</td>\n",
       "      <td>1307.357057</td>\n",
       "      <td>2012-12-29</td>\n",
       "      <td>52</td>\n",
       "      <td>12</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277718</th>\n",
       "      <td>2012-12-29</td>\n",
       "      <td>54</td>\n",
       "      <td>73</td>\n",
       "      <td>53.337413</td>\n",
       "      <td>2012-12-29</td>\n",
       "      <td>52</td>\n",
       "      <td>12</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>277719 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            day_id  but_num_business_unit  dpt_num_department     turnover  \\\n",
       "0       2017-09-30                     64                 127   580.308443   \n",
       "1       2017-09-30                    119                 127  1512.995918   \n",
       "2       2017-09-30                      4                  88   668.593556   \n",
       "3       2017-09-30                    425                 127     0.000000   \n",
       "4       2017-09-30                    513                  73     0.000000   \n",
       "...            ...                    ...                 ...          ...   \n",
       "277714  2012-12-29                    131                  73     1.461821   \n",
       "277715  2012-12-29                    237                 127   759.283046   \n",
       "277716  2012-12-29                    129                 117  1716.399152   \n",
       "277717  2012-12-29                    468                 127  1307.357057   \n",
       "277718  2012-12-29                     54                  73    53.337413   \n",
       "\n",
       "              day  week  month  year  \n",
       "0      2017-09-30    39      9  2017  \n",
       "1      2017-09-30    39      9  2017  \n",
       "2      2017-09-30    39      9  2017  \n",
       "3      2017-09-30    39      9  2017  \n",
       "4      2017-09-30    39      9  2017  \n",
       "...           ...   ...    ...   ...  \n",
       "277714 2012-12-29    52     12  2012  \n",
       "277715 2012-12-29    52     12  2012  \n",
       "277716 2012-12-29    52     12  2012  \n",
       "277717 2012-12-29    52     12  2012  \n",
       "277718 2012-12-29    52     12  2012  \n",
       "\n",
       "[277719 rows x 8 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed4345ae-1e66-4e72-8f01-c3b3b5256890",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_week_data = train[train['day_id'] == train['day_id'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "490b1d8e-4fce-4837-be4f-6a882895b139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the naive forecast function\n",
    "def naive_forecast(train, test):\n",
    "    last_week_data = train[train['day_id'] == train['day_id'].max()]\n",
    "    predictions = []\n",
    "    for _, row in test.iterrows():\n",
    "        but_num_business_unit = row['but_num_business_unit']\n",
    "        dpt_num_department = row['dpt_num_department']\n",
    "        last_turnover = last_week_data[(last_week_data['but_num_business_unit'] == but_num_business_unit) & \n",
    "                                       (last_week_data['dpt_num_department'] == dpt_num_department)]['turnover'].values[0]\n",
    "        predictions.append(last_turnover)\n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9df8e99-44f6-403d-954e-117e22ef1234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the moving average forecast function\n",
    "def moving_average_forecast(train, test, window=4):\n",
    "    predictions = []\n",
    "    for _, row in test.iterrows():\n",
    "        but_num_business_unit = row['but_num_business_unit']\n",
    "        dpt_num_department = row['dpt_num_department']\n",
    "        relevant_data = train[(train['but_num_business_unit'] == but_num_business_unit) & \n",
    "                              (train['dpt_num_department'] == dpt_num_department)].sort_values(by='day')\n",
    "        last_n_weeks_data = relevant_data['turnover'].tail(window)\n",
    "        avg_turnover = last_n_weeks_data.mean()\n",
    "        predictions.append(avg_turnover)\n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "623fea10-6428-46aa-a6a3-67b54d67e703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d5f463d-131f-41c9-be4d-79efc3b2a6c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2017-09-30 00:00:00')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['day'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb5b038-03e0-40e1-8c06-f5099288a2a7",
   "metadata": {},
   "source": [
    "# split train dataset to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0253dd51-9a67-472f-a739-a6982a90cf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "weeks = train[train['day_id'] =='2017-09-30']['week'].max() -7\n",
    "year = train[train['day_id'] =='2017-09-30']['year'].max() -7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "441353ca-25d3-4282-9870-659c68d78d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "validation_time = train['day'].max() - timedelta(weeks=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966bf3cf-f7fb-493b-812e-1331e8f01b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Walk-Forward Validation to evaluate baseline model\n",
    "\n",
    "# Split data into training and validation sets\n",
    "train_data = train[train['day']<=validation_time]  # Use all but the last 8 weeks for training\n",
    "validation_data = train[train['day']>validation_time] # Last 8 weeks for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e023cc-1916-47b6-be36-c8ee0da94721",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data.drop(\"turnover\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938bda42-ed26-485a-a6b8-82962d11fd0f",
   "metadata": {},
   "source": [
    "# baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97effb9-c5ad-48db-9efa-75bbb90b4212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive forecast\n",
    "naive_predictions = naive_forecast(train_data, validation_data)\n",
    "\n",
    "# moving average forecast\n",
    "moving_avg_predictions = moving_average_forecast(train_data, validation_data, window=4)\n",
    "\n",
    "\n",
    "# Add predictions to the test dataset\n",
    "validation_data['naive_forecast'] = naive_predictions\n",
    "validation_data['moving_avg_forecast'] = moving_avg_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8151a022-8691-4b71-abfe-8b107e66f76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_naive = validation_data['naive_forecast'].values\n",
    "predictions_avg= validation_data['moving_avg_forecast'].values\n",
    "actuals = validation_data['Turnover'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74efcf6d-5eae-4f77-873b-5e9c40f80a51",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_19763/3304060653.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Evaluate the baseline model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactuals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions_naive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# Evaluate the baseline model\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "\n",
    "mae = mean_absolute_error(actuals, predictions_naive)\n",
    "mse = mean_squared_error(actuals, predictions_naive)\n",
    "rmse = mean_squared_error(actuals, predictions_naive, squared=False)\n",
    "\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10c485e-5a69-4597-b3b5-6a92a16ad865",
   "metadata": {},
   "source": [
    "# 3. MVP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bf9708-8cd8-40e0-b179-fbd335c28420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "\n",
    "# Load the data\n",
    "train = pd.read_parquet('path/to/train.parquet')\n",
    "test = pd.read_parquet('path/to/test.parquet')\n",
    "\n",
    "# Prepare the data for Prophet\n",
    "# Convert the 'week' column to datetime (assuming the 'week' column is in YYYY-WW format)\n",
    "train['ds'] = pd.to_datetime(train['week'].astype(str) + '-1', format='%Y-%W-%w')\n",
    "train = train.rename(columns={'turnover': 'y'})\n",
    "\n",
    "# Separate forecasts for each store-department combination\n",
    "forecasts = []\n",
    "\n",
    "for but_num_business_unit in train['but_num_business_unit'].unique():\n",
    "    for dpt_num_department in train['dpt_num_department'].unique():\n",
    "        # Filter data for the current store and department\n",
    "        store_dept_data = train[(train['but_num_business_unit'] == but_num_business_unit) & (train['dpt_num_department'] == dpt_num_department)]\n",
    "        \n",
    "        # Check if there's enough data to train the model\n",
    "        if len(store_dept_data) > 8:  # Ensure at least some data points\n",
    "            # Initialize and fit the model\n",
    "            model = Prophet()\n",
    "            model.fit(store_dept_data[['ds', 'y']])\n",
    "            \n",
    "            # Create a dataframe for future dates\n",
    "            future = model.make_future_dataframe(periods=8, freq='W')\n",
    "            \n",
    "            # Predict future turnover\n",
    "            forecast = model.predict(future)\n",
    "            \n",
    "            # Extract the relevant part of the forecast\n",
    "            forecast = forecast[['ds', 'yhat']].tail(8)\n",
    "            forecast['but_num_business_unit'] = but_num_business_unit\n",
    "            forecast['dpt_num_department'] = dpt_num_department\n",
    "            \n",
    "            forecasts.append(forecast)\n",
    "\n",
    "# Combine all forecasts into a single dataframe\n",
    "forecast_df = pd.concat(forecasts)\n",
    "\n",
    "# Merge the forecasts with the test dataset\n",
    "test['week'] = pd.to_datetime(test['week'].astype(str) + '-1', format='%Y-%W-%w')\n",
    "merged_test = test.merge(forecast_df, left_on=['but_num_business_unit', 'dpt_num_department', 'week'], right_on=['but_num_business_unit', 'dpt_num_department', 'ds'], how='left')\n",
    "\n",
    "# Save the predictions to a file\n",
    "merged_test[['but_num_business_unit', 'dpt_num_department', 'week', 'yhat']].to_csv('prophet_forecasts.csv', index=False)\n",
    "\n",
    "print(\"Prophet forecasts saved to 'prophet_forecasts.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfe5924-2b89-4b0a-a306-c3141e6f0e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21da9544-a3b4-4718-a83d-bdd56666ebc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Assuming the actual turnover values are available in the test dataset\n",
    "actual_turnover = test['actual_turnover']\n",
    "\n",
    "# Calculate MAE and RMSE for Prophet forecast\n",
    "mae_prophet = mean_absolute_error(actual_turnover, merged_test['yhat'])\n",
    "rmse_prophet = np.sqrt(mean_squared_error(actual_turnover, merged_test['yhat']))\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Prophet Forecast - MAE: {mae_prophet}, RMSE: {rmse_prophet}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2aa5c6-6605-4cd2-98f7-288629011c51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90c820b4-cabe-4a60-9a75-59a42fd9014e",
   "metadata": {},
   "source": [
    "# MLOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8057a5df-25d7-453a-b4cc-c3ac403a331f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model\n",
    "with open('prophet_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591c65b3-656b-4652-8e91-ef4816b169df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "\n",
    "# Load the model\n",
    "with open('prophet_model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.get_json()\n",
    "    future_dates = pd.DataFrame(data['dates'], columns=['ds'])\n",
    "    forecast = model.predict(future_dates)\n",
    "    return jsonify(forecast[['ds', 'yhat']].to_dict(orient='records'))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a32c4e-1cc3-4d04-94a5-9ad06ecd77e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m105",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m105"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
